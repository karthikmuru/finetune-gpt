{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb19b644",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, TextDataset, DataCollatorForLanguageModeling, Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b17b3e7",
   "metadata": {},
   "source": [
    "## 1. Import the lyrics dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e21de990",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv('taylor_swift_lyrics.csv', encoding='latin1')\n",
    "text = []\n",
    "\n",
    "for title in d['track_title'].unique():\n",
    "    song = \"\"\n",
    "    for l in d[d['track_title'] == title]['lyric']:\n",
    "        song += l + ' \\n '\n",
    "    text.append(song + ' <|endoftext|>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7890e65",
   "metadata": {},
   "source": [
    "### Sample from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f065c307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I didn't know what I would find \n",
      " When I went looking for a reason, I know \n",
      " I didn't read between the lines \n",
      " And, baby, I've got nowhere to go \n",
      " I tried to take the road less traveled by \n",
      " But nothing seems to work the first few times \n",
      " Am I right? \n",
      " So how can I ever try to be better? \n",
      " Nobody ever lets me in \n",
      " I can still see you, this ain't the best view \n",
      " On the outside looking in \n",
      " I've been a lot of lonely places \n",
      " I've never been on the outside \n",
      " You saw me there, but never knew \n",
      " I would give it all up to be \n",
      " A part of this, a part of you \n",
      " And now it's all too late so you see \n",
      " You could've helped if you had wanted to \n",
      " But no one notices until it's too \n",
      " Late to do anything \n",
      " So how can I ever try to be better? \n",
      " Nobody ever lets me in \n",
      " I can still see you, this ain't the best view \n",
      " On the outside looking in \n",
      " I've been a lot of lonely places \n",
      " I've never been on the outside \n",
      " So how can I ever try to be better? \n",
      " Nobody ever lets me in \n",
      " I can still see you, this ain't the best view \n",
      " On the outside looking in \n",
      " I've been a lot of lonely places \n",
      " I've never been on the outside \n",
      "  <|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "print(text[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1468d9f3",
   "metadata": {},
   "source": [
    "## 2. Finetuning the pretrained GPT2 model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fcf87c",
   "metadata": {},
   "source": [
    "### Creating the dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34643261",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch.cuda\n",
    "import torch\n",
    "\n",
    "class CustomTextDataset(Dataset):\n",
    "    def __init__(self, tokenizer, text, block_size):\n",
    "        self.examples = tokenizer.batch_encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=block_size,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples[\"input_ids\"])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.examples.items()}\n",
    "        return item"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d02bb5a",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d6a98bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/karthik/miniconda3/envs/cgpt/lib/python3.10/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [47/47 00:27, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning complete. Model saved to: ../models/ts1\n"
     ]
    }
   ],
   "source": [
    "def fine_tune_gpt2(output_dir, model_name=\"gpt2\", epochs=1, batch_size=2, learning_rate=1e-4):\n",
    "    # Load the pretrained GPT-2 model and tokenizer\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_name, pad_token_id=tokenizer.eos_token_id)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "    tokenized_text = tokenizer.encode(text)\n",
    "\n",
    "    dataset = CustomTextDataset(tokenizer, text, block_size=128)  # Adjust block_size as per your requirements\n",
    "\n",
    "\n",
    "    # Create a data collator for language modeling\n",
    "    data_collator = DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer,\n",
    "        mlm=False\n",
    "    )\n",
    "\n",
    "    # Define the training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        overwrite_output_dir=True,\n",
    "        num_train_epochs=epochs,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        learning_rate=learning_rate,\n",
    "        save_steps=500,  # Save checkpoints every 500 steps\n",
    "        save_total_limit=2,\n",
    "        fp16=True  # Only keep the last 2 checkpoints\n",
    "    )\n",
    "\n",
    "    # Create a Trainer instance\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        data_collator=data_collator,\n",
    "        train_dataset=dataset\n",
    "    )\n",
    "\n",
    "    # Fine-tune the model\n",
    "    trainer.train()\n",
    "\n",
    "    # Save the fine-tuned model\n",
    "    trainer.save_model(output_dir)\n",
    "    \n",
    "    del model\n",
    "    del tokenizer\n",
    "    del trainer\n",
    "\n",
    "    print(\"Fine-tuning complete. Model saved to:\", output_dir)\n",
    "\n",
    "\n",
    "output_dir = \"../models/ts1\"\n",
    "\n",
    "fine_tune_gpt2(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db79fe3",
   "metadata": {},
   "source": [
    "## 3. Generating new Lyrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937b191f",
   "metadata": {},
   "source": [
    "### Load finetuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef8177d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fine_tuned_model(model_dir):\n",
    "    # Load the fine-tuned GPT-2 model and tokenizer\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_dir)\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "    return model, tokenizer\n",
    "\n",
    "model, tokenizer = load_fine_tuned_model(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926b1f75",
   "metadata": {},
   "source": [
    "### Generate Lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6320f545",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, tokenizer, prompt_text, max_length=300):\n",
    "    input_ids = tokenizer.encode(prompt_text, return_tensors=\"pt\")\n",
    "    output = model.generate(\n",
    "        input_ids, \n",
    "        do_sample=True, \n",
    "        max_length=max_length, \n",
    "        top_p=0.92, \n",
    "        top_k=0\n",
    "    )\n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    \n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8b63746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text:\n",
      "beautiful summer \n",
      "\n",
      " And what a beautiful moment of arrival \n",
      " When something terrible happened \n",
      " My own pain was wanting to smile \n",
      " When it came crashing down \n",
      " And I stood alone, my heart pounding \n",
      " Let alone you \n",
      " But I did my best to convince you \n",
      " But me like that \n",
      " So that's the way it ended \n",
      " And it was good \n",
      " So don't look back, though \n",
      " Because I didn't have the drive \n",
      " Because I had to ask \n",
      " 'Cause you keep lying \n",
      " And it'll go either way \n",
      " And you keep going, and you keep going, and you get lost in the beat of eternity \n",
      " And I 1910~05 \n",
      " I took my woman camping, and \n",
      " And after a long ride home, we were still at the dock when we spotted a blue light \n",
      " And what a love story \n",
      " Don't believe me \n",
      " Just like you always tell me \n",
      " But just like you always tell me \n",
      " So how long ago \n",
      " Come home in the back yard and tell me the story \n",
      " But you still lie \n",
      " Just like you always tell me \n",
      " You're not the best time \n",
      " But just like me like you always tell me \n",
      " And never you'll ever know \n",
      " But you'll never know you \n",
      " How far they walk till you see \n",
      " And that's when they're a minute away from the lighthouse\n"
     ]
    }
   ],
   "source": [
    "prompt = \"beautiful summer\"\n",
    "generated_text = generate_text(model, tokenizer, prompt)\n",
    "\n",
    "print(\"Generated Text:\")\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d2d0a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834e8d38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
